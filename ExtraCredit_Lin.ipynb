{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LqVPysbUT9o"
      },
      "outputs": [],
      "source": [
        "# only need to run once per session\n",
        "!pip install -q -U keras-tuner\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gdown\n",
        "\n",
        "#Use the h5 file from my drive\n",
        "file_id = \"1-1lCaTKdlHjUBVvdHuUJTaRimrINcdXS\"\n",
        "!gdown --id $file_id -O best_model.h5\n",
        "\n",
        "# confirm\n",
        "!ls -lh best_model.h5\n"
      ],
      "metadata": {
        "id": "LhRVkTluVPad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fashion-MNIST Extra Credit Notebook\n",
        "# Requirements:\n",
        "# - >98% validation accuracy on Fashion-MNIST\n",
        "# - Checkpoints, EarlyStopping, Dropout, Hyperparameter tuning, TensorBoard\n",
        "# - Save final model as .h5 and load it\n",
        "\n",
        "# 1. Install dependencies\n",
        "!pip install -q -U keras-tuner visualkeras\n",
        "\n",
        "# 2. Enable TensorBoard\n",
        "%load_ext tensorboard\n",
        "\n",
        "# 3. Imports\n",
        "import os, datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "import keras_tuner as kt\n",
        "\n",
        "model = keras.models.load_model(\"best_model.h5\")\n",
        "\n",
        "# 4. Load & preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "# split off 5k for validation\n",
        "x_train, x_val = x_train[:-5000], x_train[-5000:]\n",
        "y_train, y_val = y_train[:-5000], y_train[-5000:]\n",
        "# normalize & reshape\n",
        "x_train = x_train.astype(\"float32\")/255.0\n",
        "x_val   = x_val.astype(\"float32\")/255.0\n",
        "x_test  = x_test.astype(\"float32\")/255.0\n",
        "x_train = x_train[..., None]\n",
        "x_val   = x_val[..., None]\n",
        "x_test  = x_test[..., None]\n",
        "\n",
        "# 5. Define hypermodel builder\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input((28,28,1)))\n",
        "    # Conv block 1\n",
        "    model.add(layers.Conv2D(\n",
        "        hp.Choice('filters1',[32,64,96]), 3, padding='same', activation='relu'\n",
        "    ))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D())\n",
        "    # Conv block 2\n",
        "    model.add(layers.Conv2D(\n",
        "        hp.Choice('filters2',[64,128,192]), 3, padding='same', activation='relu'\n",
        "    ))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D())\n",
        "    # Dense head\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dropout(hp.Float('dropout1',0.2,0.5,step=0.1)))\n",
        "    model.add(layers.Dense(\n",
        "        hp.Int('dense_units', 128, 512, step=128), activation='relu'\n",
        "    ))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(hp.Float('dropout2',0.2,0.5,step=0.1)))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    # Compile\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate',[1e-2,1e-3,1e-4])\n",
        "        ),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# 6. Set up KerasTuner (Hyperband)\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='kt_dir',\n",
        "    project_name='fashion_extra'\n",
        ")\n",
        "# callbacks for tuning\n",
        "stop_early = callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "log_dir = os.path.join('logs', datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
        "tb_tuner = callbacks.TensorBoard(log_dir=log_dir)\n",
        "\n",
        "# 7. Run hyperparameter search\n",
        "tuner.search(\n",
        "    x_train, y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[stop_early, tb_tuner]\n",
        ")\n",
        "\n",
        "# 8. Build the best model\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# 9. Final training with checkpoints & early stopping\n",
        "checkpoint_cb = callbacks.ModelCheckpoint(\n",
        "    'best_model.h5', save_best_only=True, monitor='val_accuracy'\n",
        ")\n",
        "early_cb = callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy', patience=5, restore_best_weights=True\n",
        ")\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=30,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[checkpoint_cb, early_cb, tb_tuner]\n",
        ")\n",
        "\n",
        "# 10. Load and evaluate the saved model\n",
        "loaded = keras.models.load_model('best_model.h5')\n",
        "loss, acc = loaded.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'Test accuracy: {acc*100:.2f}%')\n",
        "\n",
        "# 11. Launch TensorBoard\n",
        "%tensorboard --logdir logs\n"
      ],
      "metadata": {
        "id": "QAt4DlMbVGeo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}